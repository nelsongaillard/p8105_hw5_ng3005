---
title: "p8105_hw5_ng3005"
author: "Nelson Gaillard"
date: "2025-11-12"
output: github_document
---

```{r, message = FALSE}
library(tidyverse)
library(rvest)
library(broom)
```



## Problem 2

##### Generate `mu` and `p-value`

```{r}
sim = function(n, mu, sigma) {
  x = rnorm(n, mean = mu, sd = sigma)
  ttest = t.test(x, mu = 0) 

  tibble(
    mu_hat = ttest$estimate,
    p_value = ttest$p.value
  )
}
```

##### Run 6 simulations for `mu`

```{r}
set.seed(1)

results = map(0:6, function(mu) {
  map(1:5000, ~sim(n = 30, mu = mu, sigma = 5)) |> 
  bind_rows() |> 
    mutate(true_mu = mu)
  }) |> 
  bind_rows()
```

##### Association between effect size and power

Compute power for each `mu`

```{r}
power_df = results |> 
  group_by(true_mu) |> 
  summarize(power = mean(p_value < 0.05))
```

Plot of `power` vs `mu`

```{r}
power_df |> 
  ggplot(aes(x = true_mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    x = "True mean (mu)",
    y = "Power (Probability of rejecting H_0",
    title = "Power as Effect Size Increases"
  )
```

As shown in the plot, as the true mean (mu) increases, the probability of rejecting the null hypothesis (H_0) increases. The data level off around 1.00 when `mu = 5` and `mu = 6`.

Compute `mu_hat` means

```{r}
summary_df = results |> 
  group_by(true_mu) |> 
  summarize(
    mean_mu_hat = mean(mu_hat),
    mean_mu_hat_sig = mean(mu_hat[p_value < 0.05])
  )
```

Create plot

```{r}
summary_df |> 
  ggplot(aes(true_mu)) +
  geom_line(aes(y = mean_mu_hat), color = "blue") +
  geom_point(aes(y = mean_mu_hat), color = "blue") +
  geom_line(aes(y = mean_mu_hat_sig), color = "red") +
  geom_point(aes(y = mean_mu_hat_sig), color = "red") +
  labs(
    x = "True mean (mu)",
    y = "Average (mu_hat)",
    title  = "Average mu_hat vs mu"
  )
```

Based on the plot, the sample average of `mu_hat` across tests for which the null is reject is approximately equal to the true value of `mu` when `mu ≥ 4`. For small effect sizes, however, the average `mu_hat` is greater than the true `mu`. This happens due to bias, and when we increase the statistical power (i.e. when `mu ≥ 4`), the bias is mitigated.



## Problem 3

##### Load in the data

```{r}
washington_post =
  read_csv("data/homicide-data.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names()
```

This dataset includes the number of homicides in various cities throughout the US. The data includes the date of the incident (`reported_date`), the victims' names (`victims_last`, `victims_first`), the race of the victim (`victim_race`), the age of the victim (`victim_age`), the sex of the victim (`victim_sex`), the location of the incident (`city`, `state`, `lat`, `lon`), and the perpetrator's disposition (`disposition`). 

##### Create `city_state` variable

```{r}
washington_post =
  washington_post |> 
  mutate(city_state = paste(city, state, sep = ", "),
         unsolved = disposition %in% c("Closed without arrest", "Open/No arrest")
  )
```

##### Summarize total homicides and number of unsolved cases in each city

```{r}
washington_post |> 
  group_by(city_state) |> 
  summarize(
    total_homicides = n(),
    unsolved_cases = sum(unsolved)
  ) |> 
  head(10) |> 
  knitr::kable()
```

##### Calculate proportion of unsolved homicides in Baltimore, MD

```{r}
washington_post |> 
  filter(city_state == "Baltimore, MD")

x = sum(washington_post$unsolved)
n = nrow(washington_post)

prop.test(x, n) |> 
  broom::tidy() |> 
  select(estimate, conf.low, conf.high) |> 
  knitr::kable()
```




