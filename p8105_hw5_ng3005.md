p8105_hw5_ng3005
================
Nelson Gaillard
2025-11-12

``` r
library(tidyverse)
library(rvest)
library(broom)
```

## Problem 2

##### Generate `mu` and `p-value`

``` r
sim = function(n, mu, sigma) {
  x = rnorm(n, mean = mu, sd = sigma)
  ttest = t.test(x, mu = 0) 

  tibble(
    mu_hat = ttest$estimate,
    p_value = ttest$p.value
  )
}
```

##### Run 6 simulations for `mu`

``` r
set.seed(1)

results = map(0:6, function(mu) {
  map(1:5000, ~sim(n = 30, mu = mu, sigma = 5)) |> 
  bind_rows() |> 
    mutate(true_mu = mu)
  }) |> 
  bind_rows()
```

##### Association between effect size and power

Compute power for each `mu`

``` r
power_df = results |> 
  group_by(true_mu) |> 
  summarize(power = mean(p_value < 0.05))
```

Plot of `power` vs `mu`

``` r
power_df |> 
  ggplot(aes(x = true_mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    x = "True mean (mu)",
    y = "Power (Probability of rejecting H_0",
    title = "Power as Effect Size Increases"
  )
```

![](p8105_hw5_ng3005_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

As shown in the plot, as the true mean (mu) increases, the probability
of rejecting the null hypothesis (H_0) increases. The data level off
around 1.00 when `mu = 5` and `mu = 6`.

Compute `mu_hat` means

``` r
summary_df = results |> 
  group_by(true_mu) |> 
  summarize(
    mean_mu_hat = mean(mu_hat),
    mean_mu_hat_sig = mean(mu_hat[p_value < 0.05])
  )
```

Create plot

``` r
summary_df |> 
  ggplot(aes(true_mu)) +
  geom_line(aes(y = mean_mu_hat), color = "blue") +
  geom_point(aes(y = mean_mu_hat), color = "blue") +
  geom_line(aes(y = mean_mu_hat_sig), color = "red") +
  geom_point(aes(y = mean_mu_hat_sig), color = "red") +
  labs(
    x = "True mean (mu)",
    y = "Average (mu_hat)",
    title  = "Average mu_hat vs mu"
  )
```

![](p8105_hw5_ng3005_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->

Based on the plot, the sample average of `mu_hat` across tests for which
the null is reject is approximately equal to the true value of `mu` when
`mu ≥ 4`. For small effect sizes, however, the average `mu_hat` is
greater than the true `mu`. This happens due to bias, and when we
increase the statistical power (i.e. when `mu ≥ 4`), the bias is
mitigated.
